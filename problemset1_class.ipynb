{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "babc34ca-f2eb-4a41-9c78-7d528e130d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84fc96-be96-4f5c-86ff-bade4ba46f2a",
   "metadata": {},
   "source": [
    "* 강의를 위해서 임의의 dataset을 준비함 예제로 보면 된다.\n",
    "* Data는 장미과와 국화과의 A효소, B효소, C효소, D효소를 측정한 값이라고 가정\n",
    "* Label은 각 sample이 장미인지(0) 국화인지(1)에 대한 정보라고 가정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "592d1158-83f5-4435-82e7-347ddc81db7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # 꽃의 수\n",
    "num_feature = 4 # A B C D\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X_batch = torch.randn(batch_size, num_feature)\n",
    "Y_batch = (torch.sum(X_batch, dim=1)>0).type(torch.float).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ec932745-2ccf-49ef-8151-734f49d278b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
       "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
       "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
       "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
       "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
       "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
       "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
       "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
       "        [-0.5181, -0.3067, -1.5810,  1.7066]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_batch # row는 첫 번째 꽃에 대한 ABCD 효소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d2e965e2-6f85-4ce7-bcf3-57c740a5da8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [0.],\n",
       "        [1.],\n",
       "        [1.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1341f7cc-69ea-4069-a811-c0b98314713b",
   "metadata": {},
   "source": [
    "## single neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf0b0bfe-a15b-4306-b6a5-8a9c933ef6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2910],\n",
      "        [ 3.0975],\n",
      "        [ 1.6780],\n",
      "        [ 1.0120],\n",
      "        [ 1.4991],\n",
      "        [-0.5044],\n",
      "        [ 1.4891],\n",
      "        [ 1.3363],\n",
      "        [ 0.2980],\n",
      "        [-1.8288]])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn(num_feature, 1) # 입력 크기, 출력 크기\n",
    "b = 1\n",
    "Z = torch.matmul(X_batch, W) + b\n",
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "948d6fb6-0da9-4679-b0cf-afbb368b1e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.2910],\n",
      "        [ 3.0975],\n",
      "        [ 1.6780],\n",
      "        [ 1.0120],\n",
      "        [ 1.4991],\n",
      "        [-0.5044],\n",
      "        [ 1.4891],\n",
      "        [ 1.3363],\n",
      "        [ 0.2980],\n",
      "        [-1.8288]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OH\\AppData\\Local\\Temp\\ipykernel_11020\\2857332262.py:3: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matricesor `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at  C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\TensorShape.cpp:2985.)\n",
      "  z_loop[i,:] = torch.matmul(W.T, X_batch[i,:].T) + b # 뒤에 X_batch는 전치를 왜 함? 안 해도 값이 같음\n"
     ]
    }
   ],
   "source": [
    "z_loop = torch.empty(batch_size, 1)\n",
    "for i in torch.arange(batch_size):\n",
    "    z_loop[i,:] = torch.matmul(W.T, X_batch[i,:].T) + b # 뒤에 X_batch는 전치를 왜 함? 안 해도 값이 같음\n",
    "print(z_loop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ba8b286-df73-4f97-8363-26707645d0d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.2910],\n",
      "        [3.0975],\n",
      "        [1.6780],\n",
      "        [1.0120],\n",
      "        [1.4991],\n",
      "        [0.0000],\n",
      "        [1.4891],\n",
      "        [1.3363],\n",
      "        [0.2980],\n",
      "        [0.0000]])\n"
     ]
    }
   ],
   "source": [
    "def ReLU(Z):\n",
    "    Z = torch.clamp(Z, min = 0)\n",
    "    return Z\n",
    "    \n",
    "A = ReLU(Z)\n",
    "print(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a0f09e-2819-45cf-93e7-26a396bc3ed1",
   "metadata": {},
   "source": [
    "## Single Layer Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00043d2d-1782-4e19-a801-ee524db7908e",
   "metadata": {},
   "source": [
    "* 한개의 Layer에 K = 5개의 neuron이 있는 network를 구성하고 출력을 구하세요\n",
    "* Activation function은 모든 neuron에 ReLU를 적용\n",
    "* 모든 weight는 Gaussian 분포를 랜덤으로 생성 torch.randn()\n",
    "* i 번째 neuron의 weight들을 W_i라고 할 때\n",
    "* W = [W_1, W_2, W_3, W_4, W_5]라고 하고, weight matrix W를 만드세요\n",
    "* W = torch.randn(??, ??)로 생성\n",
    "* Bias 역시 b라는 tensor에 저장하고, 각 neuron 별로 1로 설정\n",
    "* b = torch.ones(??, ??)\n",
    "* 아래 problem 2-2에서 수업에서 배운 Z 행렬과 A 행렬을 구하세요"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b98a1a-53d3-4c66-b46c-99c33cf6b5c1",
   "metadata": {},
   "source": [
    "## problem 2-1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19850c6-0f28-45bf-b81f-f5caafd3656e",
   "metadata": {},
   "source": [
    "* Z 행렬과 A 행렬의 차원은 어떻게 나오는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d2b3b85c-531d-43e1-a8df-377dfe82b199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답 : Z = np.randn(B = 10, 5), A = np.randn(B = 10, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7841f6-a95e-45dd-9660-d3a2b3482567",
   "metadata": {},
   "source": [
    "## problem 2-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d7e3841-febc-4ced-8b31-7d68b0a7032c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X =  tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
      "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
      "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
      "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
      "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
      "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
      "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
      "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
      "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
      "        [-0.5181, -0.3067, -1.5810,  1.7066]])\n",
      "W =  tensor([[ 2.0553e-01, -4.5033e-01, -5.7308e-01, -5.5536e-01, -1.1256e+00],\n",
      "        [-3.1700e-01, -1.0925e+00, -8.5194e-02, -9.3348e-02,  6.8705e-01],\n",
      "        [-8.3832e-01,  8.9182e-04, -7.5043e-01,  1.8541e-01,  6.2114e-01],\n",
      "        [ 6.3818e-01, -2.4600e-01,  2.3025e+00, -1.8817e+00, -4.9727e-02]])\n",
      "b =  tensor([[1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1.]])\n",
      "Z =  tensor([[ 1.0671,  2.8724,  0.9324,  2.5028,  1.3414],\n",
      "        [-0.1299,  0.3819, -4.1785,  4.3857,  0.4290],\n",
      "        [ 1.3700,  2.1595,  1.3698,  0.4240, -0.0287],\n",
      "        [-0.4617, -0.3442, -0.5815,  1.4903,  2.4214],\n",
      "        [ 1.2910,  3.2672,  3.3215,  0.5214,  1.6699],\n",
      "        [ 3.0848,  1.9731,  5.3120, -2.7375, -1.0467],\n",
      "        [ 0.8850,  1.8451,  1.3625,  0.8050,  1.0694],\n",
      "        [ 0.7048,  1.7004,  1.5791,  0.4140,  1.2880],\n",
      "        [ 2.2235,  0.3659,  1.1929,  0.1104, -1.0415],\n",
      "        [ 3.4053,  1.1471,  6.4390, -2.1882,  0.3055]])\n",
      "A =  tensor([[1.0671, 2.8724, 0.9324, 2.5028, 1.3414],\n",
      "        [0.0000, 0.3819, 0.0000, 4.3857, 0.4290],\n",
      "        [1.3700, 2.1595, 1.3698, 0.4240, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 1.4903, 2.4214],\n",
      "        [1.2910, 3.2672, 3.3215, 0.5214, 1.6699],\n",
      "        [3.0848, 1.9731, 5.3120, 0.0000, 0.0000],\n",
      "        [0.8850, 1.8451, 1.3625, 0.8050, 1.0694],\n",
      "        [0.7048, 1.7004, 1.5791, 0.4140, 1.2880],\n",
      "        [2.2235, 0.3659, 1.1929, 0.1104, 0.0000],\n",
      "        [3.4053, 1.1471, 6.4390, 0.0000, 0.3055]])\n",
      "XW =  tensor([[ 0.0671,  1.8724, -0.0676,  1.5028,  0.3414],\n",
      "        [-1.1299, -0.6181, -5.1785,  3.3857, -0.5710],\n",
      "        [ 0.3700,  1.1595,  0.3698, -0.5760, -1.0287],\n",
      "        [-1.4617, -1.3442, -1.5815,  0.4903,  1.4214],\n",
      "        [ 0.2910,  2.2672,  2.3215, -0.4786,  0.6699],\n",
      "        [ 2.0848,  0.9731,  4.3120, -3.7375, -2.0467],\n",
      "        [-0.1150,  0.8451,  0.3625, -0.1950,  0.0694],\n",
      "        [-0.2952,  0.7004,  0.5791, -0.5860,  0.2880],\n",
      "        [ 1.2235, -0.6341,  0.1929, -0.8896, -2.0415],\n",
      "        [ 2.4053,  0.1471,  5.4390, -3.1882, -0.6945]])\n",
      "X.shape =  torch.Size([10, 4])\n",
      "W.shape =  torch.Size([4, 5])\n",
      "b.shape =  torch.Size([10, 5])\n",
      "Z.shape =  torch.Size([10, 5])\n",
      "A.shape =  torch.Size([10, 5])\n",
      "WX.shape =  torch.Size([10, 5])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "\n",
    "X = torch.randn(batch_size, num_feature)\n",
    "W = torch.randn(num_feature, 5)\n",
    "b = torch.ones((batch_size, 5))\n",
    "Z = np.matmul(X_batch, W) + b\n",
    "A = ReLU(Z)\n",
    "XW = np.matmul(X, W)\n",
    "\n",
    "print('X = ', X)\n",
    "print('W = ', W)\n",
    "print('b = ', b)\n",
    "print('Z = ', Z)\n",
    "print('A = ', A)\n",
    "print('XW = ', XW)\n",
    "print('X.shape = ', X.shape)\n",
    "print('W.shape = ', W.shape)\n",
    "print('b.shape = ', b.shape)\n",
    "print('Z.shape = ', Z.shape)\n",
    "print('A.shape = ', A.shape)\n",
    "print('WX.shape = ', XW.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75908a98-7af8-490f-8158-fa27e95b374d",
   "metadata": {},
   "source": [
    "## problem 3\n",
    "* x(3)를 입력으로하는 2번째 neuron의 결과값을 출력하세요\n",
    "* 위에서 구한 Z[i, j] 인덱싱을 통해서 출력하세요\n",
    "* python의 인덱싱은 0부터 시작한다는 것을 주의하세요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b7a38062-a2b3-4b6d-b3e1-115543868b27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b4f87411-0fd2-41a0-9968-e081c4ea9be8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1258, -1.1524, -0.2506, -0.4339],\n",
       "        [ 0.8487,  0.6920, -0.3160, -2.1152],\n",
       "        [ 0.3223, -1.2633,  0.3500,  0.3081],\n",
       "        [ 0.1198,  1.2377,  1.1168, -0.2473],\n",
       "        [-1.3527, -1.6959,  0.5667,  0.7935],\n",
       "        [ 0.5988, -1.5551, -0.3414,  1.8530],\n",
       "        [-0.2159, -0.7425,  0.5627,  0.2596],\n",
       "        [-0.1740, -0.6787,  0.9383,  0.4889],\n",
       "        [ 1.2032,  0.0845, -1.2001, -0.0048],\n",
       "        [-0.5181, -0.3067, -1.5810,  1.7066]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70d339c1-1b35-4113-88a7-46b1b79f1c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.3223, -1.2633,  0.3500,  0.3081])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f73419b4-0f3a-41d5-8929-d08fc3cd8c68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.0553e-01, -4.5033e-01, -5.7308e-01, -5.5536e-01, -1.1256e+00],\n",
       "        [-3.1700e-01, -1.0925e+00, -8.5194e-02, -9.3348e-02,  6.8705e-01],\n",
       "        [-8.3832e-01,  8.9182e-04, -7.5043e-01,  1.8541e-01,  6.2114e-01],\n",
       "        [ 6.3818e-01, -2.4600e-01,  2.3025e+00, -1.8817e+00, -4.9727e-02]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50d43df0-3cce-4801-a002-cac0bde50012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.5033e-01],\n",
       "        [-1.0925e+00],\n",
       "        [ 8.9182e-04],\n",
       "        [-2.4600e-01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W[:,1].reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0722672-2761-4a97-9364-fce21817b77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a51db7d-3304-437a-bf08-605dee181b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.3700, 2.1595, 1.3698, 0.4240, 0.0000])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = np.matmul(X[2], W[:,]) + b[2]\n",
    "# Z\n",
    "A = ReLU(Z)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "48c95c84-d184-47f7-9ade-c5e1fc5586f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer = tensor(2.1595)\n"
     ]
    }
   ],
   "source": [
    "print('answer =', A[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8c07a-554e-488c-a7c9-07db295a7b40",
   "metadata": {},
   "source": [
    "## problem 4: Multi-Layer network\n",
    "* 3개의 layer가 있는 network를 구성\n",
    "* 2번째 layer의 입력 크기는 k[1] = 16, 출력 크기는 k[2] = 6\n",
    "* 마지막 layer의 출력은 k[3] = 1개의 neuron으로 구성\n",
    "* 각 layer의 연산값을 구하시오\n",
    "    * 각 layer의 선형 변환 결과값은 Z1, Z2, Z3로 저장\n",
    "    * 각 layer의 결과값은 A1, A2, A3로 저장\n",
    "* 모든 weight는 Gaussian 랜덤 변수로 생성, bias는 1로 구성된 벡터로 생성\n",
    "* 각 layer의 weight는 W1, W2, W3로 하고, bias는 b1, b2, b3로 생성\n",
    "* Activation 함수는 ReLU를 적용\n",
    "* Loop 없이 행렬연산으로 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8de442f8-9a2c-468d-a61b-bed83400412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = torch.randn(num_feature, 16)\n",
    "W2 = torch.randn(16, 6)\n",
    "W3 = torch.randn(6, 1)\n",
    "\n",
    "b1 = torch.ones((batch_size, 16))\n",
    "b2 = torch.ones((batch_size, 6))\n",
    "b3 = torch.ones((batch_size, 1))\n",
    "\n",
    "Z1 = torch.matmul(X_batch, W1) + b1\n",
    "A1 = ReLU(Z1)\n",
    "Z2 = torch.matmul(A1, W2) + b2\n",
    "A2 = ReLU(Z2)\n",
    "Z3 = torch.matmul(A2, W3) + b3\n",
    "A3 = ReLU(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d4933bbb-0fc5-4e58-8885-16f35a99807e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 16])\n",
      "tensor([[ 1.3895,  2.7307,  0.4425,  1.5148, -0.5831,  2.6471,  2.2709,  1.7535,\n",
      "          0.2448,  1.5904, -0.7494,  3.0297,  3.6558, -0.5646,  0.5738,  0.1979],\n",
      "        [ 5.1927,  1.5904, -0.8478,  5.3809,  1.4204, -1.9857, -1.1945,  3.7331,\n",
      "          2.9422,  1.1654,  0.3122,  1.3705,  1.0481,  2.7797,  4.6984,  2.2839],\n",
      "        [ 1.6287,  1.3993,  0.7631,  2.1163,  2.6092,  3.9219,  1.9780, -0.5877,\n",
      "         -0.4297,  0.7422,  0.7852,  3.0681,  1.6857,  1.2953,  0.0256, -0.8328],\n",
      "        [-1.3477,  0.7864, -0.5992,  0.0969, -0.0293, -3.3191,  0.6593,  0.4956,\n",
      "          0.8589,  1.5405,  0.5275, -2.1166, -1.1360,  1.9938,  2.5719,  3.4393],\n",
      "        [-1.5183,  2.5148,  0.6834, -0.6490, -0.3412,  4.0840,  3.8433, -0.8106,\n",
      "         -1.6353,  1.5724, -0.6586,  2.6544,  3.1000, -0.9549, -1.3304, -0.4940],\n",
      "        [ 1.1630, -0.1191,  3.5546,  0.1057,  4.2038,  7.3419,  2.2010, -1.7828,\n",
      "         -0.4161, -0.2162,  2.9292,  3.6366,  1.3462,  0.6885, -2.6723, -2.6269],\n",
      "        [ 0.0890,  1.5841,  0.3984,  0.8864,  1.0644,  2.1056,  2.1286, -0.2614,\n",
      "         -0.3747,  1.1863,  0.2939,  1.6717,  1.4300,  0.8149,  0.3401,  0.3616],\n",
      "        [-0.8300,  1.4673,  0.1819,  0.3787,  1.1066,  1.7874,  2.3870, -0.9687,\n",
      "         -0.8224,  1.2334,  0.2850,  1.1385,  0.9101,  0.9872,  0.1926,  0.5469],\n",
      "        [ 4.6161, -0.3222,  2.8484,  2.8075,  3.6868,  3.0597, -0.6922,  1.9302,\n",
      "          2.7217, -0.1253,  3.0841,  2.4737,  0.7905,  1.9221,  0.9085, -0.3954],\n",
      "        [ 0.5329, -0.4048,  5.0435, -2.1895,  1.2758,  5.2208,  1.3277,  1.0891,\n",
      "          1.7293,  0.0986,  3.2487,  1.9156,  1.8901, -1.1327, -2.5217, -0.9805]])\n"
     ]
    }
   ],
   "source": [
    "print(Z1.shape)\n",
    "print(Z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "48381320-30fb-4cc0-b383-502d3f031424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "tensor([[  1.9137,  -1.0062,   2.3766,   6.1688,  -8.5389,   4.9134],\n",
      "        [-13.9765,  -2.4794,  -4.6007,  11.3645, -14.5665,  -7.4800],\n",
      "        [  7.8733,  -7.0355,  -1.1037,  -3.3914,  -2.9546,   1.7027],\n",
      "        [ -6.5202,  -3.6515,  -4.9261,   4.7627,  -2.3993,  -1.0504],\n",
      "        [  7.1427,  -1.5242,   4.5426,   0.4195,  -4.1756,   8.2852],\n",
      "        [ 25.5169,  -9.5745,   0.3278,  -5.6337,   1.1771,   5.1426],\n",
      "        [  3.0988,  -4.3540,  -0.2907,  -1.1413,  -1.3359,   1.8877],\n",
      "        [  3.7680,  -5.6240,   0.3110,  -1.0453,  -0.8318,   1.1303],\n",
      "        [ 14.4201,  -2.8338,  -2.8916,   2.4184, -11.2742,  -5.7170],\n",
      "        [ 23.7240,   1.3002,   2.4048,   1.1020,  -3.9789,   3.0966]])\n"
     ]
    }
   ],
   "source": [
    "print(Z2.shape)\n",
    "print(Z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eeeaf9e9-b236-400e-b857-de2339856bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 8.3970],\n",
      "        [ 7.4530],\n",
      "        [ 8.3471],\n",
      "        [ 3.7044],\n",
      "        [10.9065],\n",
      "        [23.7129],\n",
      "        [ 4.5640],\n",
      "        [ 4.6411],\n",
      "        [14.1077],\n",
      "        [22.1548]])\n"
     ]
    }
   ],
   "source": [
    "print(Z3.shape)\n",
    "print(Z3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2fa0bb46-61a8-484e-bd69-1c30678e11a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[ 8.3970],\n",
      "        [ 7.4530],\n",
      "        [ 8.3471],\n",
      "        [ 3.7044],\n",
      "        [10.9065],\n",
      "        [23.7129],\n",
      "        [ 4.5640],\n",
      "        [ 4.6411],\n",
      "        [14.1077],\n",
      "        [22.1548]])\n"
     ]
    }
   ],
   "source": [
    "print(A3.shape)\n",
    "print(A3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5215b879-0c2c-4ee9-831d-5612bc4343ad",
   "metadata": {},
   "source": [
    "## problem 5\n",
    "* 위에서 구한 A3[i,j]의 인덱싱을 통해서 h(x(3))을 출력\n",
    "* 역시 python 인덱싱은 0부터 시작한다는 것을 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "31288d6b-a710-4463-baa0-0f1fc8c00254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_theta(x3) =  tensor([3.7044])\n"
     ]
    }
   ],
   "source": [
    "print('h_theta(x3) = ', A3[3,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1477178-a204-429e-8c76-8d522b385637",
   "metadata": {},
   "source": [
    "## problem 6\n",
    "* 위에서 공부한 것을 함수로 만들어 본다. 아래 한 layer의 선형 변환을 연산하는 class를 만들어보자\n",
    "* Class는 my_linear_layer()\n",
    "    * __init__(self, n_input_, n_output) 함수:\n",
    "        * self.W 변수 초기화: Weight 행렬 self.W를 랜덤 Gaussian 생성(차원에 맞는)\n",
    "        * self.b 변수 초기화: bias 행렬 self.b를 모두 1인 벡터 생성(차원에 맞는)\n",
    "    * forward(A) 함수:\n",
    "        * 입력: A는 sample batch X 또는 전 layer에서 들어오는 입력 batch A[L-1]을 입력하는 자리\n",
    "        * return 값\n",
    "            * Z 변수는 A[L-1]의 선형 변환 값, 즉 Z[L]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f8bfd93c-0e69-48d9-94a2-0b5a9b2d7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class my_linear_layer():\n",
    "#     def __init__(self, n_input, n_output):\n",
    "#         self.n_input = n_input\n",
    "#         self.n_output = n_output\n",
    "        \n",
    "#         self.W = []\n",
    "#         self.b = []\n",
    "        \n",
    "#         for i in range(1, 5):\n",
    "#             if i == 0:\n",
    "#                 self.W.append(np.random.randn(n_input, 5))\n",
    "#                 self.b.append(np.random.randn(10, 5))\n",
    "            \n",
    "#             elif i < 5:\n",
    "#                 self.W[i].append(np.random.randn(4, n_output))\n",
    "#                 self.b[i].append(np.random.randn(10, n_output))\n",
    "                \n",
    "#             else:\n",
    "#                 self.W.append(np.random.randn(4, 5))\n",
    "#                 self.W.append(np.random.randn(1, 5))\n",
    "                \n",
    "#     def forward(self, x):\n",
    "#         self.Z = []\n",
    "#         self.A = []\n",
    "        \n",
    "#         for i in range(1, 5):\n",
    "#             if i < 5:\n",
    "#                 self.Z = np.matmul(x, self.W[i]) + self.b[i]\n",
    "#                 self.Z.append(self.Z)\n",
    "#                 self.A = ReLU(self.Z)\n",
    "#                 self.A.append(self.A)\n",
    "    \n",
    "#     # print(Z)\n",
    "#     # print(A)\n",
    "#         return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db10319f-46b2-4a0b-af0c-bc66b28dfcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62b3836a-1a03-4f38-b70b-640ce3aa9dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10 # 꽃의 수\n",
    "num_feature = 4 # A B C D\n",
    "torch.manual_seed(0)\n",
    "\n",
    "X_batch = torch.randn(batch_size, num_feature)\n",
    "Y_batch = (torch.sum(X_batch, dim=1)>0).type(torch.float).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b7eeb680-f13c-4f4e-a0d3-4a2578d3097f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class my_linear_layer():\n",
    "    def __init__(self, n_input, n_output):\n",
    "        self.n_input = n_input\n",
    "        self.n_output = n_output\n",
    "        \n",
    "        self.W = torch.randn(n_input, n_output)\n",
    "        self.b = torch.ones((1, n_output))\n",
    "        \n",
    "    def forward(self, A):\n",
    "        Z = np.matmul(A, self.W)\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c83fbe7-f4c3-4230-a5b5-cd0ae362c7e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0259, -0.8468, -0.2874, -0.9014, -1.2395],\n",
       "        [ 1.1053,  0.3770, -2.3077, -1.5116, -3.4858],\n",
       "        [ 3.2555,  0.3657,  0.1774, -1.2346,  0.5884],\n",
       "        [-3.7106, -0.0888, -1.0279,  0.3927,  2.2091],\n",
       "        [ 0.6620, -0.8805,  0.6564, -0.5711,  1.8937],\n",
       "        [ 4.5180,  0.8361,  2.4116,  0.1107,  1.2406],\n",
       "        [ 0.7660, -0.1162, -0.0184, -0.6416,  1.2296],\n",
       "        [ 0.2537, -0.0804,  0.0118, -0.5609,  2.2824],\n",
       "        [ 3.2380,  1.0130,  0.7145,  0.1075, -2.5468],\n",
       "        [ 0.5108, -0.0874,  2.9933,  2.2403, -0.6644]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mll = my_linear_layer(num_feature, 5) #인스턴스\n",
    "mll.forward(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bc406d97-0129-489b-a5d6-a928977908fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.9415,  0.7915, -0.0203, -0.4372, -0.2188],\n",
      "        [-2.4351, -0.0729, -0.0340,  0.9625,  0.3492],\n",
      "        [-0.9215, -0.0562, -0.6227, -0.4637,  1.9218],\n",
      "        [-0.4025,  0.1239,  1.1648,  0.9234,  1.3873]])\n",
      "tensor([[1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(mll.W)\n",
    "print(mll.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7090b544-718b-40d1-96c7-69965736afb3",
   "metadata": {},
   "source": [
    "## Building a Linear Layer with torch.nn\n",
    "* 위에서 수행한 작업은 pytorch에서는 torch.nn.Linear라는 명령어로 쉽게 구현 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "aa2a67f3-efb9-49c1-810d-39b0c60c79f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2961,  0.7004, -0.8614,  0.2921, -0.5018],\n",
       "        [-0.1483,  0.0637, -0.1383,  0.4197, -0.8470],\n",
       "        [ 0.1854,  0.1652, -0.2639,  0.1737, -0.0945],\n",
       "        [-0.0614,  0.6224, -0.4242,  0.1581, -0.1709],\n",
       "        [ 0.3559,  0.9299, -1.0427,  0.2574,  0.0060],\n",
       "        [ 0.6099, -0.5685,  0.6088, -0.6778, -0.0804],\n",
       "        [ 0.1734,  0.4933, -0.5239,  0.1931, -0.1087],\n",
       "        [ 0.1284,  0.5906, -0.5904,  0.2340,  0.0529],\n",
       "        [ 0.4184, -0.8945,  0.9784, -0.6714, -0.7855],\n",
       "        [ 0.9594, -0.6232,  0.8436, -1.3285, -0.7340]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "W = torch.randn(num_feature, 5)\n",
    "L1 = nn.Linear(num_feature, 5)\n",
    "Zll = L1(X_batch)\n",
    "Zll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966d8a75-7229-41dd-b8f4-9dd64bd50676",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### 강의에서의 숫자랑 다른데 ###############\n",
    "############### 다시 해 보기 ###############\n",
    "############### 우선 첫 번째 연습 ###############"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
